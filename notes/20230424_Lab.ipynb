{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BLB7sHVoFFvn"
   },
   "source": [
    "# Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DRVX0ZExFHcG"
   },
   "source": [
    "The Benchmark class includes various methods that help in constructing a model, training, evaluating its performance, and visualizing the training progress using TensorFlow. \n",
    "\n",
    "Your objective is to implement the MyBenchmark class, which inherits from the Benchmark class and performs simple linear regression.\n",
    "\n",
    "\n",
    "Follow these steps to complete the task:\n",
    "\n",
    "* Inherit the MyBenchmark class from the Benchmark class.\n",
    "\n",
    "* Implement the dataset method to create a simple dataset for linear regression.\n",
    "\n",
    "* Implement the make_hyper_params method to define hyperparameters for the linear regression model.\n",
    "\n",
    "* Implement the make_model method to construct the linear regression model using TensorFlow.\n",
    "\n",
    "* Implement the get_result method to retrieve the training results such as loss.\n",
    "\n",
    "* Initialize an instance of the MyBenchmark class.\n",
    "\n",
    "* Transform the input data using the transform_data method.\n",
    "\n",
    "* Define training parameters, including the number of epochs, batch size, and any required callbacks.\n",
    "\n",
    "* Train and evaluate the linear regression model using the benchmark method.\n",
    "\n",
    "* Visualize the training results, such as loss and predictions, using the provided plotting methods.\n",
    "\n",
    "Additionally, explore and make use of the following advanced features provided by the Benchmark class:\n",
    "\n",
    "* Save and load the trained model using the save_model and load_model methods.\n",
    "* Implement model checkpoints to save the model every N epochs or save the best model using the make_checkpoint_callback method.\n",
    "* Visualize the training progress using TensorBoard by employing the make_tensorboard_callback method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "fn0M6_DWFNJP"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from tensorflow.keras.losses import MeanSquaredError, MeanAbsoluteError\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "AKfb-dc2E_kT"
   },
   "outputs": [],
   "source": [
    "class Benchmark:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        pass\n",
    "\n",
    "    def dataset(self, train_size=100):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def min_max_scaler(self, data):\n",
    "        scaler = MinMaxScaler()\n",
    "        return scaler.fit_transform(data)\n",
    "\n",
    "    def standard_scaler(self, data):\n",
    "        scaler = StandardScaler()\n",
    "        return scaler.fit_transform(data)\n",
    "\n",
    "    def transform_data(self, x, y, y_label, scaler):\n",
    "        X = scaler(x)\n",
    "        Y = scaler(y.reshape(-1, 1))\n",
    "        return X, Y\n",
    "\n",
    "    def make_hyper_params(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def make_optimizer(self, name, lr):\n",
    "        print('make_optimizer', name)\n",
    "        if name == 'Adam':\n",
    "            return Adam(learning_rate=lr)\n",
    "        elif name == 'RMSprop':\n",
    "            return RMSprop(learning_rate=lr)\n",
    "        elif name == 'SGD':\n",
    "            return SGD(learning_rate=lr)            \n",
    "        else:\n",
    "            raise ValueError('Unknown optimizer')\n",
    "\n",
    "    def make_loss_func(self, name):\n",
    "        if name == 'MAE':\n",
    "            return MeanAbsoluteError()\n",
    "        elif name == 'MSE':\n",
    "            return MeanSquaredError()            \n",
    "        else:\n",
    "            raise ValueError('Unknown loss function')\n",
    "\n",
    "    def make_model(self, opt='Adam', lr='0.01', loss_fn='MSE', **kargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def train(self, model, X, y, epochs=50, batch=1, callbacks=None, **kargs):\n",
    "        model.fit(X, y, epochs=epochs, batch_size=batch, callbacks=callbacks)\n",
    "\n",
    "    def evaluate(self, model, X_test, y_test):\n",
    "        return model.evaluate(X_test, y_test)\n",
    "\n",
    "    def predict(self, model, X):\n",
    "        return model.predict(X)\n",
    "\n",
    "    def get_result(self, model, record):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def plot_result(self, data, ylabel, xlabel='epochs'):\n",
    "        plt.plot(data)\n",
    "        plt.xlabel(xlabel)\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_predict(self, model, X_train, y_true):\n",
    "        y_pred = self.predict(model, X_train)\n",
    "        plt.plot(y_true, label='True')\n",
    "        plt.plot(y_pred, label='Predicted')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def save_model(self, model, filename):\n",
    "        model.save(filename)\n",
    "\n",
    "\n",
    "    def load_model(self, filename):\n",
    "        return tf.keras.models.load_model(filename)\n",
    "\n",
    "\n",
    "    def make_checkpoint_callback(self, save_best_only=True, period=5):\n",
    "        filepath = 'model_checkpoint.h5'\n",
    "        checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, save_best_only=save_best_only, save_weights_only=False, monitor='val_loss',\n",
    "                                    mode='min', verbose=1, save_freq='epoch', period=period)\n",
    "        return checkpoint\n",
    "\n",
    "\n",
    "    # def make_tensorboard_callback(self, log_dir='./logs'):\n",
    "    #     tensorboard = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True, write_images=True,\n",
    "    #                               update_freq='epoch', profile_batch=2, embeddings_freq=1)\n",
    "    #     return tensorboard\n",
    "\n",
    "\n",
    "    def benchmark(self, X, y, params=None):\n",
    "        import sys\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        hyper_params = self.make_hyper_params() if params is None else params\n",
    "        min_loss = sys.float_info.max \n",
    "        for param in hyper_params:\n",
    "          print('*'*20)\n",
    "          print('opt: {}, lr: {}, loss_fn: {}, batch: {}'\\\n",
    "                .format(param['opt'], param['lr'], param['loss_fn'], param['batch']))\n",
    "          model = self.make_model(**param)\n",
    "          record = self.train(model, X_train, y_train, **param)\n",
    "          result = self.get_result(model, record)\n",
    "          print('result', result)\n",
    "          score = self.evaluate(model, X_test, y_test)\n",
    "          if result['loss'][-1] < min_loss:\n",
    "            print('loss: {:.2f}, weights: {}, bias: {}'.format(result['loss'][-1], result['weights'], result['bias']))\n",
    "          return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Jzvr0dF2FLyZ"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (2518482068.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[3], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    #  implement your code\u001b[0m\n\u001b[1;37m                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "class MyBenchmark(Benchmark):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aYR5UTm7Fi_G"
   },
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hTN90iDHFUGH"
   },
   "outputs": [],
   "source": [
    "my_benchmark = MyBenchmark(train_size=100)\n",
    "X_transformed, y_transformed = my_benchmark.transform_data(my_benchmark.X, my_benchmark.y, 'Y', my_benchmark.standard_scaler)\n",
    "train_params = [{\n",
    "  'epochs': 50,\n",
    "  'batch': 1,\n",
    "  'loss_fn': 'MAE',\n",
    "  'lr': 0.1,\n",
    "  'opt': 'Adam',\n",
    "  'callbacks': [\n",
    "      my_benchmark.make_checkpoint_callback(save_best_only=True, period=5),\n",
    "      #my_benchmark.make_tensorboard_callback(log_dir='./logs')\n",
    "  ]  \n",
    "}]\n",
    "score = my_benchmark.benchmark(X_transformed, y_transformed, train_params)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
